{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b998c735-2c26-497d-977c-fe46b866ba05",
   "metadata": {},
   "source": [
    "# Prédiction de Pannes avec XGBoost et Calibration des Probabilités\n",
    "\n",
    "## Problématique\n",
    "\n",
    "Dans de nombreux systèmes industriels, la prédiction des pannes est necessaire pour la maintenance préventive et la réduction des temps d'arrêt. Cependant, les pannes sont souvent des événements rares, ce qui rend la tâche de prédiction difficile. Ce notebook présente une approche pour prédire les pannes en utilisant un modèle de classification XGBoost, suivi d'une calibration des probabilités pour améliorer la fiabilité des prédictions.\n",
    "\n",
    "Nous simulons également le cas où il y a de nouvelle données rentrée par l'utilisateur de facons à observé les cas de dérive des données.\n",
    "\n",
    "*Glossaire de la maintenance :* \n",
    "- $MTBF$ et $MTBUR$ : Mean Time Between Failure/Unschedulled-Removal, lié à la fiabilité du système. Principalement utilisé dans l'electronique.\n",
    "- $RUL$ : Remaining Usefull life, lié à la durée de vie restante. Principalement utilisé dans les sytèmes avec usure (ex : pneu).\n",
    "\n",
    "L'objectif de la maintenance prédictive correspond à prédire la prochaine panne à partir de signaux faibles. C'est à dire, des signaux qui n'ont pas de corrélation linéaire évidente, mais qui sont énonciateur d'un phénomène (pouvant amener à une corrélation linéaire ou non).\n",
    "\n",
    "## Objectifs\n",
    "\n",
    "1. **Générer un Dataset Synthétique** : Utiliser `make_classification` de `sklearn` pour créer un dataset avec des pannes rares.\n",
    "2. **Enregistrer les Données dans PostgreSQL** : Sauvegarder les données générées dans une base de données PostgreSQL.\n",
    "3. **Charger les Données depuis PostgreSQL** : Charger les données pour l'entraînement et l'évaluation du modèle.\n",
    "4. **Entraîner un Modèle XGBoost** : Entraîner un modèle XGBoost pour la classification binaire (panne/non-panne).\n",
    "5. **Calibrer les Probabilités** : Utiliser `CalibratedClassifierCV` pour calibrer les probabilités sorties par le modèle.\n",
    "6. **Évaluer les Performances** : Calculer les métriques AUC et Log Loss pour évaluer la performance du modèle.\n",
    "7. **Interprétabilité avec SHAP** : Utiliser SHAP pour expliquer les prédictions du modèle.\n",
    "8. **Détection de Drift** : Mesurer le drift des données et réentraîner le modèle si nécessaire.\n",
    "9. **Suivi avec MLflow** : Utiliser MLflow pour suivre les paramètres, les métriques et le modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d07e216-d73f-430c-91c6-6207646f4050",
   "metadata": {},
   "source": [
    "## Configuration de la Base de Données PostgreSQL\n",
    "\n",
    "Pour stocker et charger les données générées, nous allons utiliser une base de données PostgreSQL. Voici les étapes pour créer la base de données et la table nécessaire.\n",
    "\n",
    "### Installation de PostgreSQL sur Ubuntu\n",
    "\n",
    "Ouvrez un terminal et exécutez les commandes suivantes pour installer PostgreSQL :\n",
    "\n",
    "```sudo apt install postgresql postgresql-contrib```\n",
    "\n",
    "### Démarrage du Service PostgreSQL\n",
    "\n",
    "Démarrez le service PostgreSQL :\n",
    "\n",
    "```sudo systemctl start postgresql```\n",
    "\n",
    "Activez le service PostgreSQL pour qu'il démarre automatiquement au démarrage du système :\n",
    "\n",
    "```sudo systemctl enable postgresql```\n",
    "\n",
    "### Connexion à PostgreSQL\n",
    "\n",
    "Passez à l'utilisateur PostgreSQL :\n",
    "\n",
    "```sudo -i -u postgres```\n",
    "\n",
    "Connectez-vous à l'interface de ligne de commande PostgreSQL :\n",
    "\n",
    "```psql```\n",
    "\n",
    "### Étapes pour Créer la Base de Données et la Table\n",
    "\n",
    "1. **Connexion à PostgreSQL** :\n",
    "   - Assurez-vous que PostgreSQL est installé et en cours d'exécution sur votre machine.\n",
    "   - Utilisez un client PostgreSQL comme `psql` ou un outil comme pgAdmin pour exécuter les commandes SQL.\n",
    "\n",
    "2. **Création de la Base de Données** :\n",
    "   - Connectez-vous à PostgreSQL en tant qu'utilisateur avec des privilèges pour créer des bases de données.\n",
    "   - Exécutez la commande suivante pour créer une nouvelle base de données nommée `mlflow_drift_detection` :\n",
    "     ```sql\n",
    "     CREATE DATABASE mlflow_drift_detection;\n",
    "     ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35ec38e-05a5-428f-9f17-d4393fcbc924",
   "metadata": {},
   "source": [
    "## Tests Effectués\n",
    "\n",
    "- **AUC (Area Under the Curve)** : Mesure de la capacité du modèle à distinguer entre les classes.\n",
    "- **Log Loss** : Mesure de la performance du modèle en termes de probabilités prédites.\n",
    "- **Visualisation SHAP** : Interprétabilité des prédictions du modèle.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Ce notebook présente une approche complète pour la prédiction de pannes en utilisant un modèle XGBoost calibré. Les résultats sont suivis avec MLflow pour assurer la reproductibilité et la traçabilité des expériences.\n",
    "\n",
    "---\n",
    "\n",
    "# Code\n",
    "\n",
    "Le code ci-dessous implémente les étapes décrites ci-dessus. Chaque étape est encapsulée dans une classe pour une meilleure modularité et maintenabilité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a330d97-da04-4abc-ae29-3c1f74e21702",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -q numpy pandas xgboost shap scikit-learn mlflow psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87d8008-87b0-4cc1-b1c2-f81df2253a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les bibliothèques nécessaires\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691d25f0-ff45-4db9-a354-01630d3bede2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spécifier un répertoire personnalisé pour stocker les artefacts MLflow\n",
    "mlflow.set_tracking_uri(\"file:/path/to/your/custom/mlruns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e36c040-5438-4d63-adf6-8cabe6d6cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration de la connexion à PostgreSQL\n",
    "DB_CONFIG = {\n",
    "    'dbname': 'mlflow_drift_detection',\n",
    "    'user': 'your_username',\n",
    "    'password': 'your_password',\n",
    "    'host': 'your_host',\n",
    "    'port': 'your_port'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b82bfea-46c9-4a6b-bb3e-d0bb3d313a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe pour la génération du dataset\n",
    "class DataGenerator:\n",
    "    def __init__(self, n_samples=1000, n_features=20, n_informative=10, n_redundant=5,\n",
    "                 n_clusters_per_class=1, weights=[0.9, 0.1], flip_y=0, random_state=42):\n",
    "        self.n_samples = n_samples\n",
    "        self.n_features = n_features\n",
    "        self.n_informative = n_informative\n",
    "        self.n_redundant = n_redundant\n",
    "        self.n_clusters_per_class = n_clusters_per_class\n",
    "        self.weights = weights\n",
    "        self.flip_y = flip_y\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def generate_data(self):\n",
    "        X, y = make_classification(n_samples=self.n_samples, n_features=self.n_features,\n",
    "                                   n_informative=self.n_informative, n_redundant=self.n_redundant,\n",
    "                                   n_clusters_per_class=self.n_clusters_per_class,\n",
    "                                   weights=self.weights, flip_y=self.flip_y, random_state=self.random_state)\n",
    "        return train_test_split(X, y, test_size=0.2, random_state=self.random_state)\n",
    "\n",
    "    def save_to_db(self, X_train, X_test, y_train, y_test):\n",
    "        conn = psycopg2.connect(**DB_CONFIG)\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        # Insérer les données dans les tables\n",
    "        train_data = [(str(list(x)), int(y)) for x, y in zip(X_train, y_train)]\n",
    "        test_data = [(str(list(x)), int(y)) for x, y in zip(X_test, y_test)]\n",
    "\n",
    "        execute_values(cur, \"INSERT INTO train_data (feature_vector, label) VALUES %s\", train_data)\n",
    "        execute_values(cur, \"INSERT INTO test_data (feature_vector, label) VALUES %s\", test_data)\n",
    "\n",
    "        conn.commit()\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "\n",
    "# Classe pour l'entraînement du modèle XGBoost\n",
    "class XGBoostModel:\n",
    "    def __init__(self):\n",
    "        self.model = XGBClassifier(eval_metric='logloss')\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "\n",
    "# Classe pour la calibration du modèle\n",
    "class ModelCalibrator:\n",
    "    def __init__(self, model):\n",
    "        self.calibrated_model = CalibratedClassifierCV(model, method='sigmoid', cv=5)\n",
    "\n",
    "    def calibrate(self, X_train, y_train):\n",
    "        self.calibrated_model.fit(X_train, y_train)\n",
    "\n",
    "    def get_calibrated_model(self):\n",
    "        return self.calibrated_model\n",
    "\n",
    "# Classe pour l'évaluation du modèle\n",
    "class ModelEvaluator:\n",
    "    def __init__(self, model, X_test, y_test):\n",
    "        self.model = model\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "\n",
    "    def evaluate(self):\n",
    "        y_pred_proba = self.model.predict_proba(self.X_test)[:, 1]\n",
    "        auc = roc_auc_score(self.y_test, y_pred_proba)\n",
    "        logloss = log_loss(self.y_test, y_pred_proba)\n",
    "        return auc, logloss\n",
    "\n",
    "# Classe pour l'interprétabilité avec SHAP\n",
    "class SHAPExplainer:\n",
    "    def __init__(self, model, X_train, X_test):\n",
    "        self.explainer = shap.Explainer(model, X_train)\n",
    "        self.shap_values = self.explainer(X_test)\n",
    "        self.X_test = X_test  # Stocker X_test pour l'utiliser dans la méthode plot\n",
    "\n",
    "    def plot(self):\n",
    "        shap.summary_plot(self.shap_values.values, self.X_test)\n",
    "\n",
    "# Classe pour mesurer le drift des données\n",
    "class DataDriftDetector:\n",
    "    def __init__(self, base_model, new_data):\n",
    "        self.base_model = base_model\n",
    "        self.new_data = new_data\n",
    "\n",
    "    def detect_drift(self):\n",
    "        # Implémenter une méthode pour détecter le drift des données\n",
    "        # Par exemple, comparer les distributions des caractéristiques\n",
    "        # ou utiliser des techniques de détection de drift comme Population Stability Index (PSI)\n",
    "        # Pour simplifier, nous allons retourner False pour l'instant\n",
    "        return False\n",
    "\n",
    "# Classe principale pour orchestrer le processus\n",
    "class MainPipeline:\n",
    "    def __init__(self):\n",
    "        self.data_generator = DataGenerator()\n",
    "\n",
    "    def load_data_from_db(self):\n",
    "        conn = psycopg2.connect(**DB_CONFIG)\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        # Charger les données depuis les tables\n",
    "        cur.execute(\"SELECT feature_vector, label FROM train_data\")\n",
    "        train_data = cur.fetchall()\n",
    "        cur.execute(\"SELECT feature_vector, label FROM test_data\")\n",
    "        test_data = cur.fetchall()\n",
    "\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "\n",
    "        # Convertir les données en numpy arrays\n",
    "        X_train = np.array([eval(row[0]) for row in train_data])\n",
    "        y_train = np.array([row[1] for row in train_data])\n",
    "        X_test = np.array([eval(row[0]) for row in test_data])\n",
    "        y_test = np.array([row[1] for row in test_data])\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    def run(self):\n",
    "        # Vérifier si une run MLflow est déjà active et la terminer\n",
    "        if mlflow.active_run():\n",
    "            mlflow.end_run()\n",
    "\n",
    "        # Initialisation de MLflow\n",
    "        mlflow.start_run()\n",
    "\n",
    "        # Génération du dataset\n",
    "        X_train, X_test, y_train, y_test = self.data_generator.generate_data()\n",
    "\n",
    "        # Enregistrement des données dans PostgreSQL\n",
    "        self.data_generator.save_to_db(X_train, X_test, y_train, y_test)\n",
    "\n",
    "        # Chargement des données depuis PostgreSQL\n",
    "        X_train, X_test, y_train, y_test = self.load_data_from_db()\n",
    "\n",
    "        # Entraînement du modèle XGBoost\n",
    "        xgb_model = XGBoostModel()\n",
    "        xgb_model.train(X_train, y_train)\n",
    "\n",
    "        # Calibration du modèle\n",
    "        model_calibrator = ModelCalibrator(xgb_model.get_model())\n",
    "        model_calibrator.calibrate(X_train, y_train)\n",
    "        calibrated_model = model_calibrator.get_calibrated_model()\n",
    "\n",
    "        # Évaluation du modèle\n",
    "        model_evaluator = ModelEvaluator(calibrated_model, X_test, y_test)\n",
    "        auc, logloss = model_evaluator.evaluate()\n",
    "\n",
    "        # Logging des paramètres et des métriques avec MLflow\n",
    "        mlflow.log_param(\"model\", \"XGBClassifier\")\n",
    "        mlflow.log_param(\"calibration\", \"sigmoid\")\n",
    "        mlflow.log_metric(\"auc\", auc)\n",
    "        mlflow.log_metric(\"log_loss\", logloss)\n",
    "\n",
    "        # Logging du modèle avec MLflow (utiliser mlflow.sklearn pour le modèle calibré)\n",
    "        mlflow.sklearn.log_model(calibrated_model, \"model\")\n",
    "\n",
    "        # Interprétabilité avec SHAP (utiliser le modèle XGBoost sous-jacent)\n",
    "        shap_explainer = SHAPExplainer(xgb_model.get_model(), X_train, X_test)\n",
    "        shap_explainer.plot()\n",
    "\n",
    "        # Détection de drift des données\n",
    "        drift_detector = DataDriftDetector(xgb_model.get_model(), X_test)\n",
    "        drift_detected = drift_detector.detect_drift()\n",
    "\n",
    "        if drift_detected:\n",
    "            # Réentraîner le modèle si un drift est détecté\n",
    "            xgb_model.train(X_train, y_train)\n",
    "            model_calibrator.calibrate(X_train, y_train)\n",
    "            calibrated_model = model_calibrator.get_calibrated_model()\n",
    "            mlflow.sklearn.log_model(calibrated_model, \"model_retrained\")\n",
    "\n",
    "        # Fin de la run MLflow\n",
    "        mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535b47fd-ab34-4c8b-93f2-14631eccd911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exécution de la pipeline principale\n",
    "pipeline = MainPipeline()\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff2e47a-e20e-4f36-a282-2103e5ae5623",
   "metadata": {},
   "source": [
    "# Monitoring avec MLflow\n",
    "\n",
    "Pour visualiser les runs MLflow, suivez ces étapes :\n",
    "\n",
    "1. **Démarrer le Serveur MLflow** :\n",
    "   - Ouvrez un terminal et exécutez la commande suivante :\n",
    "     ```bash\n",
    "     mlflow ui\n",
    "     ```\n",
    "\n",
    "2. **Accéder à l'Interface Utilisateur Web** :\n",
    "   - Ouvrez un navigateur web et accédez à [http://localhost:5000](http://localhost:5000).\n",
    "\n",
    "3. **Explorer les Runs** :\n",
    "   - Dans l'interface utilisateur de MLflow, vous verrez une liste des runs exécutés.\n",
    "   - Cliquez sur un run pour voir les détails, y compris les paramètres, les métriques, et les artefacts.\n",
    "\n",
    "# Exemple de Run\n",
    "\n",
    "- **Run ID** : [Run ID](http://localhost:5000/#/experiments/0/runs/<run_id>)\n",
    "- **Modèle Enregistré** : [Modèle](http://localhost:5000/#/experiments/0/runs/<run_id>/artifactPath/model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "248d8966-5959-4107-a19d-c13bdfb5a632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-13 12:57:50 +0200] [17524] [INFO] Starting gunicorn 23.0.0\n",
      "[2025-04-13 12:57:50 +0200] [17524] [INFO] Listening at: http://127.0.0.1:5000 (17524)\n",
      "[2025-04-13 12:57:50 +0200] [17524] [INFO] Using worker: sync\n",
      "[2025-04-13 12:57:50 +0200] [17525] [INFO] Booting worker with pid: 17525\n",
      "[2025-04-13 12:57:50 +0200] [17526] [INFO] Booting worker with pid: 17526\n",
      "[2025-04-13 12:57:50 +0200] [17527] [INFO] Booting worker with pid: 17527\n",
      "[2025-04-13 12:57:50 +0200] [17528] [INFO] Booting worker with pid: 17528\n",
      "^C\n",
      "[2025-04-13 13:50:55 +0200] [17524] [INFO] Handling signal: int\n",
      "[2025-04-13 13:50:55 +0200] [17526] [INFO] Worker exiting (pid: 17526)\n",
      "[2025-04-13 13:50:55 +0200] [17527] [INFO] Worker exiting (pid: 17527)\n",
      "[2025-04-13 13:50:55 +0200] [17528] [INFO] Worker exiting (pid: 17528)\n",
      "[2025-04-13 13:50:55 +0200] [17525] [INFO] Worker exiting (pid: 17525)\n"
     ]
    }
   ],
   "source": [
    "# Pour tester, vous pouver lancer ici\n",
    "!mlflow ui"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
